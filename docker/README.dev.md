# MeshLib Docker Build System: Understanding the Layer-Optimized Architecture

Think of Docker's layer system like constructing a building: you want to lay the most stable, rarely-changing foundation first, then build the more dynamic elements on top. This architectural principle guides every decision in this optimized setup.

Traditional Docker usage often treats containers as ephemeral execution environments, but this approach transforms your container into a sophisticated build artifact. The container becomes a repository of compiled knowledge, where your third-party dependencies exist as pre-built, optimized libraries ready for immediate use. This shift from "build everything every time" to "build the stable parts once, iterate on the changing parts" represents a fundamental efficiency gain in your development workflow.

## Understanding the Build Phases

The restructured Dockerfile creates distinct phases that mirror the stability hierarchy of your codebase. Each phase serves a specific purpose in the overall build strategy, and understanding these phases helps you appreciate why certain changes trigger rebuilds while others don't.

### Phase 1: System Foundation

The first phase establishes the system-level dependencies and tools. This includes the Emscripten SDK, system packages, and basic user configuration. These elements change very rarely in a typical project lifecycle. When they do change, it usually indicates a major infrastructure upgrade, such as moving to a new version of Emscripten or adding fundamental build tools.

### Phase 2: Git and Submodule Initialization

The second phase handles your project's dependency graph through git submodules. This phase demonstrates a crucial insight about containerized builds: by copying your git configuration and initializing submodules within the container, we create a stable snapshot of your dependency tree. This snapshot only changes when you update your submodule references, which typically happens less frequently than your main source code changes.

The key insight here is that your thirdparty dependencies have their own lifecycle, distinct from your main application code. Libraries like imgui, parallel-hashmap, and mrbind-pybind11 might be updated monthly or even less frequently, while your main application code might change multiple times per day. By recognizing and respecting this difference in change frequency, we can optimize the build process significantly.

### Phase 3: Thirdparty Compilation

The third phase performs the computationally intensive work of compiling your third-party dependencies for all target configurations. This is where the real magic happens. Instead of rebuilding these libraries every time you change a line of application code, they're compiled once into the Docker image and then reused across all subsequent builds.

The phase builds three distinct sets of libraries: the default multithreaded 32-bit configuration, the single-threaded configuration, and the 64-bit WASM configuration. Each set gets installed to a separate location (`/usr/local/lib/emscripten*`), preventing conflicts while ensuring that each build configuration has access to appropriately compiled dependencies.

## The Caching Advantage Explained

Docker's layer caching works through content hashing. When Docker builds an image, it calculates a hash for each layer based on the instructions and the files they reference. If the hash matches a previously built layer, Docker reuses the cached layer instead of rebuilding it.

If changing a single line of source code would invalidate the cache for all subsequent layers, including the thirdparty compilation. This meant that a one-character change in your main application could trigger a complete rebuild of all dependencies, potentially adding dozens of minutes to your build time.

With the new architecture, changes to source code only affect the final phase where your application is compiled. The hours of work spent compiling third-party libraries remains cached and ready for immediate use. This transforms your iterative development cycle from "change code, wait for full rebuild" to "change code, fast incremental build."

## Volume Strategy and Build Artifact Management

The Docker Compose configuration employs a sophisticated volume strategy that balances performance, isolation, and convenience. Understanding this strategy helps you make informed decisions about when to clean caches and how to troubleshoot build issues.

The volume setup creates distinct storage areas for different types of build artifacts. Source build volumes store the compiled output of your application code, while CMake cache volumes store configuration data that speeds up subsequent CMake runs. By separating these concerns, the system can selectively invalidate caches when needed without losing valuable compilation work.

The bind mount approach for build caches creates directories on your host system, making build artifacts easily accessible for inspection and debugging. This transparency proves invaluable when you need to examine generated files or troubleshoot compilation issues.

## Configuration-Specific Optimizations

Each build configuration (default, single-threaded, 64-bit WASM) represents a different compilation strategy with distinct performance characteristics and target environments. The Docker setup respects these differences by creating separate library installations and separate cache volumes.

The default multithreaded configuration optimizes for modern multi-core processors and web environments that support shared memory. The single-threaded configuration targets environments with threading restrictions or simplifies debugging by eliminating concurrency issues. The 64-bit WASM configuration addresses applications requiring large memory spaces or advanced computational capabilities.

By pre-building libraries for all configurations, the system eliminates the need to choose a configuration at image build time. Instead, you select the appropriate configuration at runtime through environment variables, providing maximum flexibility with minimal overhead.

## Practical Usage Patterns

Understanding the architecture enables more effective usage patterns. For daily development work, you'll typically use the default configuration with `docker compose up --build meshlib-emscripten-build`. The build process completes quickly because only your application code needs compilation, while the pre-built libraries provide immediate dependency satisfaction.

When you need to test different configurations, switching between them becomes nearly instantaneous. Running `docker compose --profile singlethreaded up meshlib-emscripten-build-singlethreaded` leverages the pre-built single-threaded libraries without requiring any compilation delay.

For debugging purposes, the persistent containers provide full access to the build environment. You can execute `docker compose exec meshlib-emscripten-build bash` to enter the container and run custom build commands, examine intermediate files, or test specific compilation flags. This debugging capability proves essential when troubleshooting complex build issues or experimenting with new features.

## Maintenance and Evolution

This architecture also simplifies long-term maintenance. When you need to update third-party dependencies, you modify the submodule references and rebuild the Docker image. The new image contains updated libraries, but your application build process remains unchanged. This separation of concerns reduces the risk of breaking changes and makes dependency updates more predictable.

When you add new third-party dependencies, you extend the thirdparty build phase rather than modifying the application build process. This approach maintains the separation between stable and dynamic elements of your build system.

The system also adapts well to team environments. Once a team member builds the Docker image with updated dependencies, other team members can pull the updated image and immediately benefit from the pre-compiled libraries without needing to understand the complex dependency build process.
